{{ $pods := whereExist .Pods "ObjectMeta.Annotations.kube_filebeat" -}}

filebeat:
  prospectors:
{{- range $pod := $pods -}}
{{ $containerMap := groupBy $pod.Status.ContainerStatuses "Name" }}
{{ $configs := parseJsonSafe $pod.ObjectMeta.Annotations.kube_filebeat -}}
{{- range $conf := $configs }}
    {{ $container := coalesce (first (index $containerMap (coalesce $conf.container ""))) (first $pod.Status.ContainerStatuses) -}}
    {{ $containerId := trimPrefix $container.ContainerID "docker://" -}}
    {{ if exists (printf "/var/lib/docker/containers/%s" $containerId) }}
    {{ $res := shell (printf "cat /var/lib/docker/image/overlay2/layerdb/mounts/%s/mount-id" $containerId) -}}
    {{ $baseDir := printf "/var/lib/docker/overlay2/%s/merged" $res.Stdout }}

    -
      # Paths that should be crawled and fetched. Glob based paths.
      # To fetch all ".log" files from a specific level of subdirectories
      # /var/log/*/*.log can be used.
      # For each file found under this path, a harvester is started.
      # Make sure not file is defined twice as this can lead to unexpected behaviour.
      paths:
      {{- if exists (printf "/var/lib/docker/containers/%s/config.vs.json" $containerId) }}
        {{ $containerConfig := parseJsonSafe (shell (printf "cat /var/lib/docker/containers/%s/config.vs.json" $containerId)) -}}
        {{- range volumePath, volumeConf:= $containerConfig.MountPoints }}
        {{ $logFileData := split $conf.log,  "/" }}
        {{ $logPath := pathJoin $logFileData[:len($logFileData)-1] }}
        {{ $logFile := $logFileData[len($logFileData)-1] }}
        {{ if $logPath == $volumePath }}
        - {{ pathJoin (printf "/var/lib/docker/volumes/%s/_data" $volumeConf.Name) $logFile }}
        {{- end }}
        {{- end }}
      {{ else }}
        - {{ pathJoin $baseDir $config.log }}
      {{- end }}

      input_type: log

      # Exclude files. A list of regular expressions to match. Filebeat drops the files that
      # are matching any regular expression from the list. By default, no files are dropped.
{{- if hasField $conf "exclude_files" }}
      exclude_files:
{{- range $f := $conf.exclude_files }}
        - '{{ $f }}'
{{- end }}
{{ else }}
      exclude_files: [".gz$"]
{{- end }}

      # Ignore files which were modified more then the defined timespan in the past.
      # In case all files on your system must be read you can set this value very large.
      # Time strings like 2h (2 hours), 5m (5 minutes) can be used.
      ignore_older: {{ coalesce $conf.ignore_older "" }}

      # Close older closes the file handler for which were not modified
      # for longer then close_older
      # Time strings like 2h (2 hours), 5m (5 minutes) can be used.
      close_older: {{ coalesce $conf.close_older "" }}

      # Exclude lines. A list of regular expressions to match. It drops the lines that are
      # matching any regular expression from the list. The include_lines is called before
      # exclude_lines. By default, no lines are dropped.
      exclude_lines:
{{- range $l := $conf.exclude_lines }}
        - '{{ $l }}'
{{- end }}

      fields:
        path: {{ $conf.log }}
        pod: {{ $pod.ObjectMeta.Name }}
        namespace: {{ $pod.ObjectMeta.Namespace }}
{{- range $key, $value := $conf.fields }}
        {{ $key }}: {{ $value }}
{{- end }}{{/* end range fields */}}

      fields_under_root: true

{{- if hasField $conf "multiline" }}
{{- with $conf.multiline }}
      multiline:
        pattern: '{{ .pattern }}'
        negate: {{ coalesce .negate false }}
        match: {{ coalesce .match "after" }}
        max_lines: {{ coalesce .max_lines "500" }}
        timeout: {{ coalesce .timeout "5s" }}
{{- end }}{{/* end with */}}
{{- end -}}{{/* end multiline */}}

{{- end }}{{/* end directory exists */}}

{{- end }}{{/* end range configs */}}

{{- end }}{{/* end range $pods */}}

  # Defines how often the spooler is flushed. After idle_timeout the spooler is
  # Flush even though spool_size is not reached.
  idle_timeout: 5s
############################# Output ##########################################

# Configure what outputs to use when sending the data collected by the beat.
# Multiple outputs may be used.
output:
{{- if mapContains .Env "LOGSTASH_HOSTS" }}
  logstash:
    # The Logstash hosts
    hosts:
	{{- range $host := split .Env.LOGSTASH_HOSTS "," }}
      - {{ $host }}
	{{- end }}

    # Number of workers per Logstash host.
    worker: 1

    # Set gzip compression level.
    compression_level: 3

    # Optional load balance the events between the Logstash hosts
    loadbalance: true

    # Optional index name. The default index name depends on the each beat.
    # For Packetbeat, the default is set to packetbeat, for Topbeat
    # top topbeat and for Filebeat to filebeat.
    #index: filebeat
{{ end -}}
{{- if mapContains .Env "CONSOLE_OUTPUT" }}
  console:
{{ end -}}
